# -*- coding: utf-8 -*-
"""Copia de Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bJF1jD0UAP7JkzTu-sXbGCZPgWCLn0fK

de moment:


1.   retallar
2.   subtituls+videos
3.   Musica
4. Pujar a Drive

# Instalem llibreries üìì
"""

!pip install moviepy pydub gradio transformers
!apt update && apt install -y ffmpeg

"""CODE PER PUJAR EL VIDEO:

from google.colab import files

# Obrir l'explorador per pujar v√≠deos .mp4
uploaded = files.upload()

# Guardar els noms dels v√≠deos en una llista
video_files = [filename for filename in uploaded.keys() if filename.endswith('.mp4')]

# Mostrar els noms dels v√≠deos pujats
print("V√≠deos pujats:")
for video in video_files:
    print(f"- {video}")

"""

#from transformers import pipeline
#pipe = pipeline("automatic-speech-recognition", model="openai/whisper-small")

"""# Pujar video i retallar silencis ‚úÇÔ∏è"""

# -*- coding: utf-8 -*-

# Primer, cal instal¬∑lar les llibreries si no les tens:
# pip install moviepy numpy

from moviepy.editor import VideoFileClip, concatenate_videoclips
import numpy as np
import os

# --- PAS 0: C√ÄRREGA DEL V√çDEO (ADAPTAT PER A GOOGLE COLAB) ---
# Aquest bloc √©s un exemple de com carregar un fitxer a Colab.
# Si no fas servir Colab, substitueix la l√≠nia 'INPUT_VIDEO_PATH' m√©s avall.
try:
    from google.colab import files
    print("Executant en Google Colab. Si us plau, puja el teu fitxer de v√≠deo.")
    uploaded = files.upload()
    # Agafem el nom del primer fitxer pujat
    video_files = list(uploaded.keys())
    if not video_files:
        raise RuntimeError("No s'ha pujat cap fitxer.")
    INPUT_VIDEO_NAME = video_files[0]
except (ImportError, RuntimeError) as e:
    print(f"No s'ha pogut carregar el fitxer amb el m√®tode de Colab ({e}).")
    print("Si us plau, defineix la ruta del v√≠deo manualment a la variable 'INPUT_VIDEO_NAME'.")
    # Posa aqu√≠ el nom del teu v√≠deo si no fas servir el m√®tode de c√†rrega
    INPUT_VIDEO_NAME = "el_teu_video.mp4"

# --- PAR√ÄMETRES PRINCIPALS (AJUSTA'LS SI CAL) ---

# 1. Nom del fitxer de v√≠deo final.
OUTPUT_VIDEO_PATH = "video_final_sense_silencis.mp4"

# 2. Llindar de volum per considerar un so com a "silenci".
#    AQUEST √âS EL PAR√ÄMETRE M√âS IMPORTANT.
#    - Si el v√≠deo final dura 0 segons, BAIXA aquest valor (ex: 0.008, 0.005).
#    - Si talla massa poc, PUJA aquest valor (ex: 0.015, 0.02).
SILENCE_THRESHOLD = 0.01

# 3. Durada m√≠nima que ha de tenir un silenci per ser eliminat (en segons).
#    Les pauses naturals en parlar (m√©s curtes que aquest valor) es mantindran.
MIN_SILENCE_LEN = 0.6  # Talla silencis de 0.6 segons o m√©s.

# 4. Quant de silenci es mantindr√† al voltant dels fragments amb so (en segons).
#    Evita talls bruscos i fa que les transicions siguin m√©s naturals.
KEEP_SILENCE_MARGIN = 0.2 # Deixa un marge de 0.2 segons.

# --- FI DELS PAR√ÄMETRES ---


def find_non_silent_chunks(video_clip, silence_threshold, min_silence_len, keep_silence_margin):
    """
    Funci√≥ millorada que detecta els segments de so, els fusiona si estan
    separats per silencis curts, i hi afegeix un marge.
    Retorna una llista de tuples amb (temps_inici, temps_fi).
    """
    print("Analitzant l'√†udio per detectar segments amb so...")
    audio = video_clip.audio
    duration = video_clip.duration

    # Utilitzem un pas d'an√†lisi petit per a m√©s precisi√≥
    step = 0.05

    # 1. Obtenir nivells de volum de tot el clip
    try:
        # max_volume() √©s r√†pid i eficient
        power = np.array([audio.subclip(t, min(t + step, duration)).max_volume() for t in np.arange(0, duration, step)])
        is_loud = power > silence_threshold
    except Exception as e:
        print(f"S'ha produ√Øt un error durant l'an√†lisi de l'√†udio: {e}")
        return []

    # Diagn√≤stic clau: comprovar si s'ha detectat algun so
    num_loud_steps = np.sum(is_loud)
    if num_loud_steps == 0:
        print("\n‚ùå ALERTA: No s'ha detectat cap so per sobre del llindar de silenci.")
        print(f"   El teu llindar ('SILENCE_THRESHOLD') √©s {silence_threshold}.")
        print("   => Soluci√≥: Prova a BAIXAR aquest valor (p. ex., a 0.005) i torna a executar l'script.\n")
        return []

    print(f"Detectats {num_loud_steps} intervals de so d'un total de {len(is_loud)}.")

    # 2. Trobar els temps d'inici i final dels segments amb so
    is_loud_indices = np.where(is_loud)[0]
    edges = np.diff(is_loud_indices) != 1
    split_points = np.where(edges)[0] + 1
    loud_segments_indices = np.split(is_loud_indices, split_points)

    chunks = []
    for segment in loud_segments_indices:
        if len(segment) > 0:
            start_time = segment[0] * step
            end_time = (segment[-1] + 1) * step
            chunks.append({'start': start_time, 'end': end_time})

    if not chunks:
        return []

    # 3. Fusionar segments separats per silencis m√©s curts que 'min_silence_len'
    merged_chunks = []
    current_chunk = chunks[0]
    for next_chunk in chunks[1:]:
        silence_between = next_chunk['start'] - current_chunk['end']
        if silence_between < min_silence_len:
            # Fusionar: estenem el final del clip actual fins al final del seg√ºent
            current_chunk['end'] = next_chunk['end']
        else:
            # Guardem el clip actual i comencem un de nou
            merged_chunks.append(current_chunk)
            current_chunk = next_chunk
    merged_chunks.append(current_chunk)

    print(f"Els segments s'han fusionat en {len(merged_chunks)} clips finals.")

    # 4. Aplicar el marge de seguretat a cada clip
    final_clip_times = []
    for chunk in merged_chunks:
        start = max(0, chunk['start'] - keep_silence_margin)
        end = min(duration, chunk['end'] + keep_silence_margin)
        if end > start:
            final_clip_times.append((start, end))

    return final_clip_times


def main():
    """
    Funci√≥ principal que carrega el v√≠deo, processa els silencis i l'exporta.
    """
    if not os.path.exists(INPUT_VIDEO_NAME):
        print(f"‚ùå Error: El fitxer '{INPUT_VIDEO_NAME}' no s'ha trobat.")
        return

    print(f"Carregant el v√≠deo: '{INPUT_VIDEO_NAME}'...")
    video = VideoFileClip(INPUT_VIDEO_NAME)

    if video.audio is None:
        print("‚ùå Error: El v√≠deo no t√© pista d'√†udio.")
        video.close()
        return

    # Obtenir els temps dels clips que volem conservar
    clip_times = find_non_silent_chunks(video, SILENCE_THRESHOLD, MIN_SILENCE_LEN, KEEP_SILENCE_MARGIN)

    if not clip_times:
        print("El proc√©s s'ha aturat perqu√® no s'han trobat clips de veu per processar.")
        video.close()
        return

    # Crear els subclips a partir dels temps calculats
    final_clips = [video.subclip(start, end) for start, end in clip_times]

    print(f"Concatenant {len(final_clips)} clips de v√≠deo...")
    final_clip = concatenate_videoclips(final_clips)

    # Exportar el v√≠deo final
    print(f"\n‚úÖ Renderitzant el v√≠deo final a '{OUTPUT_VIDEO_PATH}'...")
    try:
        final_clip.write_videofile(
            OUTPUT_VIDEO_PATH,
            codec='libx264',
            audio_codec='aac',
            preset='medium',
            fps=video.fps,
            threads=os.cpu_count(),
            logger='bar'
        )
        print(f"\n‚ú® ¬°Proc√©s completat! El teu v√≠deo es troba a: '{OUTPUT_VIDEO_PATH}'")
    except Exception as e:
        print(f"\n‚ùå Error durant la renderitzaci√≥: {e}")

    # Alliberar recursos
    video.close()
    final_clip.close()

if __name__ == "__main__":
    main()

#transcription = pipe(video_files[0], return_timestamps=True)
#text = transcription['text']
#print(text)

"""PROVA DE SUBTITULS + VIDEOS"""

# --- 1. INSTALACI√ìN Y CONFIGURACI√ìN (M√âTODO ROBUSTO) ---
print("--- Instalando y configurando dependencias... ---")
!pip install openai requests -q
!apt update -qq && apt install -y ffmpeg imagemagick -qq

# --- ¬°CORRECCI√ìN DEFINITIVA! ---
# Creamos y sobrescribimos el archivo de pol√≠ticas de ImageMagick con una
# configuraci√≥n permisiva que soluciona el error "security policy".
# Este m√©todo es m√°s fiable que editar el archivo existente con 'sed'.
permissive_policy = """
<policymap>
  <policy domain="coder" rights="read|write" pattern="PS" />
  <policy domain="coder" rights="read|write" pattern="PS2" />
  <policy domain="coder" rights="read|write" pattern="PS3" />
  <policy domain="coder" rights="read|write" pattern="EPS" />
  <policy domain="coder" rights="read|write" pattern="PDF" />
  <policy domain="coder" rights="read|write" pattern="XPS" />
  <policy domain="coder" rights="read|write" pattern="MVG" />
  <policy domain="coder" rights="read|write" pattern="URL" />
  <policy domain="coder" rights="read|write" pattern="HTTPS" />
  <policy domain="coder" rights="read|write" pattern="LABEL" />
  <!-- La siguiente l√≠nea es la m√°s importante: permite a MoviePy usar archivos temporales. -->
  <policy domain="path" rights="read|write" pattern="@*" />
</policymap>
"""
with open("/etc/ImageMagick-6/policy.xml", "w") as f:
    f.write(permissive_policy)
print("‚úÖ Pol√≠tica de ImageMagick configurada correctamente.")


# --- 2. IMPORTACI√ìN DE LIBRER√çAS ---
from transformers import pipeline
from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip
import numpy as np
import os
import tempfile
import math
import requests
import json
import re
from openai import OpenAI

# --- 3. CONFIGURACI√ìN DE MOVIEPY ---
from moviepy.config import change_settings
change_settings({"IMAGEMAGICK_BINARY": "/usr/bin/convert"})


# --- 4. PAR√ÅMETROS PRINCIPALES (AJUSTA ESTO) ---
# --- Claves de API (¬°IMPORTANTE!) ---
OPENAI_API_KEY = "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"  # INSERTA TU CLAVE DE API DE OPENAI AQU√ç
PEXELS_API_KEY = "I6AkGPbPMshG5BtXtXR2hKc8T2exKlWBwRFpqoiUYjOQmZjXBvFVKVEN"  # INSERTA TU CLAVE DE API DE PEXELS AQU√ç

# --- Archivos ---
VIDEO_INPUT_PATH = "video_final_sense_silencis.mp4" # ¬°ASEG√öRATE DE SUBIR ESTE ARCHIVO!
VIDEO_OUTPUT_PATH = "video_final_con_broll_y_subs.mp4"

# --- Configuraci√≥n de Subt√≠tulos ---
WORDS_PER_CHUNK = 3

# --- Configuraci√≥n de V√≠deos de Pexels (B-Roll) ---
PEXELS_CLIP_DURATION = 8  # Duraci√≥n en segundos de cada clip de Pexels
PEXELS_CLIP_SIZE_FACTOR = 0.45 # Tama√±o del clip (0.45 = 45% del ancho del v√≠deo principal)
PEXELS_CLIP_POSITION = ("right", "top") # Posici√≥n en la pantalla


# --- 5. FUNCI√ìN PARA TRANSCRIPCI√ìN (Optimizada) ---
def transcribe_audio_chunks(video_path):
    print("\n--- Paso 1: Extrayendo y transcribiendo audio con Whisper... ---")
    try:
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_audio_file:
            audio_path = tmp_audio_file.name
        with VideoFileClip(video_path) as video_clip:
            audio = video_clip.audio
            audio.write_audiofile(audio_path, codec='pcm_s16le', fps=16000)
        pipe = pipeline("automatic-speech-recognition", model="openai/whisper-small", device=0, chunk_length_s=30)
        result = pipe(audio_path, return_timestamps=True, generate_kwargs={"language": "spanish"})
        print("‚úÖ Transcripci√≥n completada.")
        return result['chunks']
    finally:
        if 'audio_path' in locals() and os.path.exists(audio_path):
            os.remove(audio_path)

# --- 6. FUNCIONES PARA IA Y B√öSQUEDA DE V√çDEOS ---
def get_pexels_queries_from_chatgpt(full_text, api_key, video_duration):
    print("\n--- Paso 2: Consultando a ChatGPT para generar temas de b√∫squeda... ---")
    try:
        client = OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Ets un expert en generar queries d'imatges per cercar a Pexels. Has de respondre en English i una frase que faci referencia al topic o frase que no crei confusio i asseguri la imatge desitjada exemple: El video parla de motivaci√≥, no posis motivation posa box training o running in the mountain o hard training. El query debe representar el mensaje no ser el topico. "
                        "A partir d'un text, crea un query √≤ptim per obtenir un v√≠deo que reflecteixi clarament el concepte de forma visual. "
                        "Retorna una llista JSON amb 'query_pexels' (breu, general i en angl√®s) i 'timestamp' (format hh:mm:ss) basant-te en la transcripci√≥ corresponent al moment on es menciona el tema, no posis imatges m√©s enlla de la duraci√≥ del video."
                        f"\nLa durada del video es {video_duration:.2f} segons."
                        "\nExemple de resposta:\n"
                        "[\n"
                        "  {\"query_pexels\": \"man working on laptop\", \"timestamp\": \"00:01:10\"},\n"
                        "  {\"query_pexels\": \"runner in the mountain\", \"timestamp\": \"00:01:40\"},\n"
                        "  {\"query_pexels\": \"artificial intelligence robot\", \"timestamp\": \"00:02:30\"}\n"
                        "]"
                    )
                },
                {"role": "user", "content": full_text}
            ]
        )
        raw_content = response.choices[0].message.content
        clean_content = re.sub(r"```json|```", "", raw_content).strip()
        topics = json.loads(clean_content)
        print(f"‚úÖ ChatGPT ha suggerit {len(topics)} temes.")
        return topics
    except Exception as e:
        print(f"‚ùå Error al consultar a ChatGPT: {e}")
        return []

def search_and_download_pexels_videos(topics, api_key):
    print("\n--- Paso 3: Buscando y descargando v√≠deos de Pexels... ---")
    headers = {"Authorization": api_key}
    downloaded_videos = []

    for i, topic in enumerate(topics):
        query = topic["query_pexels"]
        timestamp = topic["timestamp"]
        print(f"üé¨ Buscando v√≠deo para: '{query}'")
        search_url = f"https://api.pexels.com/videos/search?query={query}&per_page=5"
        try:
            response = requests.get(search_url, headers=headers)
            response.raise_for_status()
            data = response.json().get("videos", []) # Corrected to use .json()
            if data:
                # Ordenar por calidad/popularidad y tomar el primero
                best_video = data[0]
                video_files = sorted(best_video['video_files'], key=lambda x: x['width'] * x['height'], reverse=True)
                video_url = video_files[0]['link']

                # Descargar el v√≠deo
                filename = f"pexels_{i}_{timestamp.replace(':', '-')}.mp4"
                print(f"‚¨áÔ∏è Descargando '{query}' a {filename}...")
                video_response = requests.get(video_url, stream=True)
                video_response.raise_for_status()
                with open(filename, 'wb') as f:
                    for chunk in video_response.iter_content(chunk_size=8192):
                        f.write(chunk)
                downloaded_videos.append({"timestamp": timestamp, "local_path": filename})
                print(f"‚úÖ Descargado.")
            else:
                print(f"‚ùå No se ha encontrado v√≠deo para: '{query}'")
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Error en la solicitud a Pexels para '{query}': {e}")

    print(f"\n‚úÖ Se han descargado {len(downloaded_videos)} v√≠deos de Pexels.")
    return downloaded_videos

# --- 7. FUNCI√ìN PARA CREAR Y ESTILIZAR SUBT√çTULOS ---
def create_subtitle_clip(text, video_width):
    return TextClip(text,
                    font='Arial-Bold',
                    fontsize=55,
                    color='white',
                    stroke_color='black',
                    stroke_width=2.5,
                    method='caption',
                    size=(video_width * 0.85, None),
                    align='center')

def timestamp_to_seconds(timestamp):
    parts = list(map(float, timestamp.strip().split(':'))) # Use float for potential sub-second precision
    if len(parts) == 3:
        h, m, s = parts
        return h * 3600 + m * 60 + s
    elif len(parts) == 2:
        m, s = parts
        return m * 60 + s
    # Handle potential timestamps that are just seconds (as float)
    elif len(parts) == 1:
        return parts[0]
    return 0

# --- 8. PROCESO PRINCIPAL ---
try:
    # --- Transcripci√≥n ---
    segments = transcribe_audio_chunks(VIDEO_INPUT_PATH)
    full_text = " ".join([seg['text'].strip() for seg in segments])

    # --- B√∫squeda y Descarga de B-Roll (Pexels) ---
    video_clip_temp = VideoFileClip(VIDEO_INPUT_PATH)
    video_duration = video_clip_temp.duration
    video_clip_temp.close() # Close the temporary clip

    pexels_topics = get_pexels_queries_from_chatgpt(full_text, OPENAI_API_KEY, video_duration)
    downloaded_pexels_videos = []
    if pexels_topics:
        downloaded_pexels_videos = search_and_download_pexels_videos(pexels_topics, PEXELS_API_KEY)

    # --- Creaci√≥n de Subt√≠tulos ---
    video = VideoFileClip(VIDEO_INPUT_PATH)
    w, h = video.w, video.h
    all_subtitle_clips = []
    print(f"\n--- Paso 4: Generando {WORDS_PER_CHUNK} palabras por subt√≠tulo... ---")
    for segment in segments:
        text = segment['text'].strip()
        timestamp = segment['timestamp']
        if not text: continue
        words = text.split()
        start_time, end_time = timestamp
        segment_duration = end_time - start_time
        if not words or segment_duration <= 0: continue
        time_per_word = segment_duration / len(words)
        for i in range(0, len(words), WORDS_PER_CHUNK):
            chunk_words = words[i:i + WORDS_PER_CHUNK]
            chunk_text = " ".join(chunk_words)
            chunk_start_time = start_time + (i * time_per_word)
            chunk_end_time = chunk_start_time + (len(chunk_words) * time_per_word)
            chunk_duration = chunk_end_time - chunk_start_time
            subtitle_clip = create_subtitle_clip(chunk_text, w)
            subtitle_clip = subtitle_clip.set_start(chunk_start_time).set_duration(chunk_duration)
            subtitle_clip = subtitle_clip.set_position(
                lambda t, start=chunk_start_time: ('center', h * 0.8 + 10 * math.sin((t - start) * math.pi / chunk_duration))
            )
            all_subtitle_clips.append(subtitle_clip)
    print(f"‚úÖ Se han creado {len(all_subtitle_clips)} clips de subt√≠tulos.")

    # --- Carga de v√≠deos de Pexels (VERSI√ìN CORREGIDA) ---
    print("\n--- Paso 5: Cargando v√≠deos de Pexels para la composici√≥n... ---")
    all_pexels_clips = []
    for pexels_video in downloaded_pexels_videos:
        try:
            # Ensure timestamp is in the correct format before converting
            # If the timestamp from ChatGPT is already seconds (float), timestamp_to_seconds will handle it.
            start_seconds = timestamp_to_seconds(pexels_video['timestamp'])

            # Carga el clip para poder leer su duraci√≥n real
            temp_clip = VideoFileClip(pexels_video['local_path'])

            # Usa la duraci√≥n m√°s corta: la deseada o la real del clip, para evitar errores
            final_duration = min(temp_clip.duration, PEXELS_CLIP_DURATION)

            # Apply transformations
            clip = (temp_clip
                    .set_start(start_seconds)
                    .set_duration(final_duration) # Use the safe duration we calculated
                    .resize(width=w * PEXELS_CLIP_SIZE_FACTOR)
                    .set_position(PEXELS_CLIP_POSITION))

            # Ensure the Pexels clip has audio to avoid composition errors
            if clip.audio is None:
                # If it doesn't have audio, don't try to compose it, preventing errors.
                # You could create a silent audio if necessary, but this is safer.
                pass

            all_pexels_clips.append(clip)
        except Exception as e:
            print(f"‚ö†Ô∏è Warning: Could not process clip {pexels_video['local_path']}. Error: {e}")

    print(f"‚úÖ Loaded {len(all_pexels_clips)} Pexels clips.")

    # --- Composici√≥n Final ---
    print("\n--- Paso 6: Componiendo el v√≠deo final (esto puede tardar)... ---")
    # The order is important: base video, then Pexels, then subtitles on top of everything
    final_video = CompositeVideoClip([video] + all_pexels_clips + all_subtitle_clips)
    final_video.write_videofile(VIDEO_OUTPUT_PATH,
                                codec='libx264',
                                audio_codec='aac',
                                fps=video.fps,
                                threads=4,
                                preset='medium')

    print(f"\n‚ú® Process completed! Video saved to: {VIDEO_OUTPUT_PATH}")

except Exception as e:
    print(f"\nüî¥ Error during processing: {str(e)}")
    import traceback
    traceback.print_exc()

finally:
    # Final cleanup of clips to avoid residual files
    if 'video' in locals(): video.close()
    if 'final_video' in locals(): final_video.close()
    if 'all_pexels_clips' in locals():
        for clip in all_pexels_clips:
            try:
                clip.close()
            except Exception as e:
                print(f"Error closing clip: {e}")

"""# @title üé¨ Transcriptor y Subtitulador Autom√°tico (Palabra por Palabra)

# --- 1. INSTALACI√ìN Y CONFIGURACI√ìN (M√âTODO ROBUSTO) ---
print("--- Instalando y configurando dependencias... ---")
!apt update -qq && apt install -y ffmpeg imagemagick -qq

# --- ¬°CORRECCI√ìN DEFINITIVA! ---
# Creamos y sobrescribimos el archivo de pol√≠ticas de ImageMagick con una
# configuraci√≥n permisiva que soluciona el error "security policy".
# Este m√©todo es m√°s fiable que editar el archivo existente con 'sed'.
permissive_policy = '''
<policymap>
  <policy domain="coder" rights="read|write" pattern="PS" />
  <policy domain="coder" rights="read|write" pattern="PS2" />
  <policy domain="coder" rights="read|write" pattern="PS3" />
  <policy domain="coder" rights="read|write" pattern="EPS" />
  <policy domain="coder" rights="read|write" pattern="PDF" />
  <policy domain="coder" rights="read|write" pattern="XPS" />
  <policy domain="coder" rights="read|write" pattern="MVG" />
  <policy domain="coder" rights="read|write" pattern="URL" />
  <policy domain="coder" rights="read|write" pattern="HTTPS" />
  <policy domain="coder" rights="read|write" pattern="LABEL" />
  <!-- La siguiente l√≠nea es la m√°s importante: permite a MoviePy usar archivos temporales. -->
  <policy domain="path" rights="read|write" pattern="@*" />
</policymap>
'''
with open("/etc/ImageMagick-6/policy.xml", "w") as f:
    f.write(permissive_policy)
print("‚úÖ Pol√≠tica de ImageMagick configurada correctamente.")


# --- 2. IMPORTACI√ìN DE LIBRER√çAS ---
from transformers import pipeline
from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip, AudioFileClip
import numpy as np
import os
import tempfile
import math

# --- 3. CONFIGURACI√ìN DE MOVIEPY ---
from moviepy.config import change_settings
change_settings({"IMAGEMAGICK_BINARY": "/usr/bin/convert"})


# --- 4. PAR√ÅMETROS PRINCIPALES (AJUSTA ESTO) ---
WORDS_PER_CHUNK = 3
VIDEO_INPUT_PATH = "video_final_sense_silencis.mp4" # ¬°ASEG√öRATE DE SUBIR ESTE ARCHIVO!
VIDEO_OUTPUT_PATH = "video_con_subtitulos_animados.mp4"

# --- 5. FUNCI√ìN PARA TRANSCRIPCI√ìN (Optimizada) ---
def transcribe_audio_chunks(video_path):
    print("\n--- Paso 1: Extrayendo y transcribiendo audio con Whisper... ---")
    try:
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_audio_file:
            audio_path = tmp_audio_file.name
        video_clip = VideoFileClip(video_path)
        audio = video_clip.audio
        audio.write_audiofile(audio_path, codec='pcm_s16le', fps=16000)
        audio.close()
        video_clip.close()
        pipe = pipeline("automatic-speech-recognition", model="openai/whisper-small", device=0, chunk_length_s=30)
        result = pipe(audio_path, return_timestamps=True, generate_kwargs={"language": "spanish"})
        print("‚úÖ Transcripci√≥n completada.")
        return result['chunks']
    finally:
        if 'audio_path' in locals() and os.path.exists(audio_path):
            os.remove(audio_path)

# --- 6. FUNCI√ìN PARA CREAR Y ESTILIZAR SUBT√çTULOS ---
def create_subtitle_clip(text, video_width):
    return TextClip(text,
                    font='Arial-Bold',
                    fontsize=55,
                    color='white',
                    stroke_color='black',
                    stroke_width=2.5,
                    method='caption',
                    size=(video_width * 0.85, None),
                    align='center')

# --- 7. PROCESO PRINCIPAL ---
try:
    video = VideoFileClip(VIDEO_INPUT_PATH)
    w, h = video.w, video.h
    segments = transcribe_audio_chunks(VIDEO_INPUT_PATH)
    all_subtitle_clips = []
    print(f"\n--- Paso 2: Generando {WORDS_PER_CHUNK} palabras por subt√≠tulo... ---")
    for segment in segments:
        text = segment['text'].strip()
        timestamp = segment['timestamp']
        if not text:
            continue
        words = text.split()
        start_time, end_time = timestamp
        segment_duration = end_time - start_time
        if not words or segment_duration <= 0:
            continue
        time_per_word = segment_duration / len(words)
        for i in range(0, len(words), WORDS_PER_CHUNK):
            chunk_words = words[i:i + WORDS_PER_CHUNK]
            chunk_text = " ".join(chunk_words)
            chunk_start_time = start_time + (i * time_per_word)
            chunk_end_time = chunk_start_time + (len(chunk_words) * time_per_word)
            chunk_duration = chunk_end_time - chunk_start_time
            subtitle_clip = create_subtitle_clip(chunk_text, w)
            subtitle_clip = subtitle_clip.set_start(chunk_start_time).set_duration(chunk_duration)
            subtitle_clip = subtitle_clip.set_position(
                lambda t, start=chunk_start_time: (
                    'center', h * 0.8 + 10 * math.sin((t - start) * math.pi / chunk_duration)
                )
            )
            all_subtitle_clips.append(subtitle_clip)
    print(f"‚úÖ Se han creado {len(all_subtitle_clips)} clips de subt√≠tulos.")
    print("\n--- Paso 3: Componiendo el v√≠deo final (esto puede tardar)... ---")
    final_video = CompositeVideoClip([video] + all_subtitle_clips)
    final_video.write_videofile(VIDEO_OUTPUT_PATH,
                                codec='libx264',
                                audio_codec='aac',
                                fps=video.fps,
                                threads=4,
                                preset='medium')
    video.close()
    final_video.close()
    print(f"\n‚ú® ¬°Proceso completado! V√≠deo guardado en: {VIDEO_OUTPUT_PATH}")

except Exception as e:
    print(f"\nüî¥ Error durante el procesamiento: {str(e)}")
    import traceback
    traceback.print_exc()
"""

# @title üé∂ Descargador de M√∫sica con Selecci√≥n Aleatoria Inteligente (Versi√≥n Corregida y Robusta)
# @markdown Elige un g√©nero o deja la opci√≥n "Autom√°tico" para que el script elija una consulta de b√∫squeda al azar cada vez.

#@markdown ---
#@markdown ### ‚öôÔ∏è Par√°metros de B√∫squeda
#@markdown **Elige el tipo de m√∫sica o d√©jalo en autom√°tico:**
query_category = "Cinematogr√°fico / Inspirador" #@param ["Autom√°tico (Aleatorio)", "Corporativo / Profesional", "Moderno / Tecnol√≥gico", "Ambiente / Calmado", "Cinematogr√°fico / Inspirador"]
#@markdown **Duraci√≥n deseada del v√≠deo (en minutos):**
target_duration_minutes = 15 #@param {type:"slider", min:5, max:60, step:1}
#@markdown **Margen de flexibilidad (en minutos, +/-):**
duration_flexibility_minutes = 10 #@param {type:"slider", min:1, max:10, step:1}
#@markdown ---
#@markdown ### üé≤ Opciones de Descarga
#@markdown **Seleccionar una canci√≥n al azar de los resultados encontrados:**
randomize_song_selection = True #@param {type:"boolean"}

# --- C√ìDIGO DE EJECUCI√ìN ---

# 1. Instalar/actualizar la herramienta yt-dlp de forma silenciosa
print("--- Instalando y configurando dependencias... ---")
!pip install --upgrade yt-dlp >> /dev/null
print("‚úÖ Herramienta yt-dlp instalada/actualizada.")

# 2. Importar las librer√≠as necesarias
import subprocess
import json
import os
import random

def get_search_query(category):
    """
    Devuelve una consulta de b√∫squeda optimizada basada en la categor√≠a seleccionada.
    Se han ajustado las b√∫squedas para ser m√°s efectivas.
    """
    best_queries = {
        "Corporativo / Profesional": "motivational background",
        "Moderno / Tecnol√≥gico": "upbeat tech background"
        "Ambiente / Calmado": "calm ambient instrumental",
        "Cinematogr√°fico / Inspirador": "inspirational cinematic background"
    }

    if category == "Autom√°tico (Aleatorio)":
        chosen_query = random.choice(list(best_queries.values()))
        print(f"ü§ñ Consulta aleatoria seleccionada: '{chosen_query}'")
        return chosen_query
    else:
        chosen_query = best_queries.get(category, "inspirational background music no copyright")
        print(f"üéµ Usando la consulta para la categor√≠a '{category}': '{chosen_query}'")
        return chosen_query

def buscar_y_descargar_con_yt_dlp(query, target_min, flexibility_min, randomize=True):
    """
    Busca en YouTube, encuentra videos que coincidan, selecciona uno y descarga el audio.
    Versi√≥n mejorada con manejo de errores robusto.
    """
    min_duration_sec = (target_min - flexibility_min) * 60
    max_duration_sec = (target_min + flexibility_min) * 60

    print(f"\nüîé Buscando en YouTube...")
    print(f"‚è±Ô∏è  Criterio de duraci√≥n: entre {target_min - flexibility_min} y {target_min + flexibility_min} minutos.")
    print("-" * 30)

    try:
        # Comando de b√∫squeda mejorado para capturar la salida y el error
        search_command = ['yt-dlp', '--dump-json', f"ytsearch25:{query}"]
        process = subprocess.run(search_command, capture_output=True, text=True, check=False) # check=False para manejar el error manualmente

        # Si yt-dlp devuelve un error (c√≥digo de salida no es 0)
        if process.returncode != 0:
            print(f"üî¥ yt-dlp ha fallado. C√≥digo de error: {process.returncode}")
            print("   Error detallado (stderr):")
            # Imprimimos el error que nos da yt-dlp, que es muy √∫til para depurar
            print(process.stderr)
            return

        # Si la salida est√° vac√≠a, la b√∫squeda no encontr√≥ nada
        if not process.stdout.strip():
            print("‚ùå La b√∫squeda no ha devuelto ning√∫n resultado. Prueba con otra categor√≠a o consulta.")
            return

        all_videos = [json.loads(line) for line in process.stdout.strip().split('\n')]
        matching_videos = [v for v in all_videos if v and 'duration' in v and min_duration_sec <= v['duration'] <= max_duration_sec]

        if not matching_videos:
            print("\n‚ùå No se encontraron videos que coincidan con los criterios de duraci√≥n.")
            print("   Prueba a aumentar la flexibilidad, cambiar la duraci√≥n o la categor√≠a.")
            return

        print(f"‚úÖ ¬°{len(matching_videos)} videos encontrados que cumplen los criterios!")

        if randomize:
            video_seleccionado = random.choice(matching_videos)
            print("   Seleccionando una canci√≥n al azar de la lista...")
        else:
            video_seleccionado = matching_videos[0]
            print("   Seleccionando la primera canci√≥n de la lista.")

        video_url = video_seleccionado['webpage_url']
        video_title = video_seleccionado['title']
        duration_str = f"{int(video_seleccionado['duration'] // 60)}:{int(video_seleccionado['duration'] % 60):02d}"

        print(f"\n‚ñ∂Ô∏è  Pista seleccionada: '{video_title}' ({duration_str} min)")

        output_filename_template = f"{video_title[:50]}.%(ext)s" # Acortamos el nombre para evitar problemas de longitud de archivo
        print(f"‚¨áÔ∏è  Descargando audio...")
        download_command = ['yt-dlp', '--extract-audio', '--audio-format', 'mp3', '--quiet', '-o', output_filename_template, video_url]
        subprocess.run(download_command, check=True)

        # L√≥gica para encontrar el nombre del archivo descargado de forma m√°s segura
        get_filename_command = download_command + ['--get-filename']
        sanitized_title_bytes = subprocess.check_output(get_filename_command)
        final_filename = sanitized_title_bytes.decode('utf-8').strip()

        print("\n‚ú® ¬°Descarga completada con √©xito!")
        print(f"   Archivo guardado como: {final_filename}")
        print("\n‚ö†Ô∏è IMPORTANTE: Revisa la descripci√≥n del video en YouTube para asegurarte de que la licencia permite su uso y si requiere atribuci√≥n.")
        print(f"   URL del video: {video_url}")

    except subprocess.CalledProcessError as e:
        print(f"\nüî¥ Un comando de yt-dlp ha fallado durante la descarga. Error: {e}")
    except Exception as e:
        print(f"\nüî¥ Ha ocurrido un error inesperado: {e}")
        import traceback
        traceback.print_exc()


# --- Ejecuci√≥n Principal ---
final_search_query = get_search_query(query_category)
buscar_y_descargar_con_yt_dlp(
    final_search_query,
    target_duration_minutes,
    duration_flexibility_minutes,
    randomize_song_selection
)

"""# @title üé∂ Descargador de M√∫sica con Selecci√≥n Aleatoria Inteligente (CODI INICIAL)
# @markdown Elige un g√©nero o deja la opci√≥n "Autom√°tico" para que el script elija una consulta de b√∫squeda al azar cada vez.

#@markdown ---
#@markdown ### ‚öôÔ∏è Par√°metros de B√∫squeda
#@markdown **Elige el tipo de m√∫sica o d√©jalo en autom√°tico:**
query_category = "Autom√°tico (Aleatorio)" #@param ["Autom√°tico (Aleatorio)", "Corporativo / Profesional", "Moderno / Tecnol√≥gico", "Ambiente / Calmado", "Cinematogr\xE1fico / Inspirador"]
#@markdown **Duraci√≥n deseada del v√≠deo (en minutos):**
target_duration_minutes = 5 #@param {type:"slider", min:5, max:60, step:1}
#@markdown **Margen de flexibilidad (en minutos, +/-):**
duration_flexibility_minutes = 3 #@param {type:"slider", min:1, max:10, step:1}
#@markdown ---
#@markdown ### üé≤ Opciones de Descarga
#@markdown **Seleccionar una canci√≥n al azar de los resultados encontrados:**
randomize_song_selection = True #@param {type:"boolean"}

# --- C√ìDIGO DE EJECUCI√ìN ---

# Instalar/actualizar la herramienta yt-dlp
!pip install --upgrade yt-dlp >> /dev/null
print("‚úÖ Herramienta yt-dlp instalada/actualizada.")

import subprocess
import json
import os
import random

def get_search_query(category):
    '''
    Devuelve una consulta de b√∫squeda optimizada basada en la categor√≠a seleccionada.
    '''
    best_queries = {
        "Corporativo / Profesional": "corporate motivational music royalty free",
        "Moderno / Tecnol√≥gico": "upbeat tech background",
        "Ambiente / Calmado": "calm ambient instrumental creative commons",
        "Cinematogr√°fico / Inspirador": "inspirational cinematic background"
    }

    if category == "Autom√°tico (Aleatorio)":
        chosen_query = random.choice(list(best_queries.values()))
        print(f"ü§ñ Consulta aleatoria seleccionada: '{chosen_query}'")
        return chosen_query
    else:
        chosen_query = best_queries.get(category, "inspirational background music no copyright")
        print(f"üéµ Usando la consulta para la categor√≠a '{category}': '{chosen_query}'")
        return chosen_query

def buscar_y_descargar_con_yt_dlp(query, target_min, flexibility_min, randomize=True):
    '''
    Busca en YouTube, encuentra videos que coincidan, selecciona uno y descarga el audio.
    '''
    min_duration_sec = (target_min - flexibility_min) * 60
    max_duration_sec = (target_min + flexibility_min) * 60

    print(f"\nüîé Buscando en YouTube...")
    print(f"‚è±Ô∏è Criterio de duraci√≥n: entre {target_min - flexibility_min} y {target_min + flexibility_min} minutos.")
    print("-" * 30)

    try:
        search_command = ['yt-dlp', '--dump-json', f"ytsearch25:{query}"]
        search_result = subprocess.check_output(search_command).decode('utf-8')
        all_videos = [json.loads(line) for line in search_result.strip().split('\n')]

        matching_videos = [v for v in all_videos if v.get('duration') and min_duration_sec <= v['duration'] <= max_duration_sec]

        if not matching_videos:
            print("\n‚ùå No se encontraron videos que coincidan con los criterios.")
            print("   Prueba a aumentar la flexibilidad, cambiar la duraci√≥n o la categor√≠a.")
            return

        print(f"‚úÖ ¬°{len(matching_videos)} videos encontrados que cumplen los criterios!")

        if randomize:
            video_seleccionado = random.choice(matching_videos)
            print("   Seleccionando una canci√≥n al azar de la lista...")
        else:
            video_seleccionado = matching_videos[0]
            print("   Seleccionando la primera canci√≥n de la lista.")

        video_url = video_seleccionado['webpage_url']
        video_title = video_seleccionado['title']
        duration_str = f"{int(video_seleccionado['duration'] // 60)}:{int(video_seleccionado['duration'] % 60):02d}"

        print(f"\n‚ñ∂Ô∏è Pista seleccionada: '{video_title}' ({duration_str} min)")

        output_filename_template = "%(title)s.%(ext)s"
        print(f"‚¨áÔ∏è Descargando audio...")
        download_command = ['yt-dlp', '--extract-audio', '--audio-format', 'mp3', '--quiet', '-o', output_filename_template, video_url]
        subprocess.run(download_command, check=True)

        sanitized_title = ""
        try:
            get_filename_command = download_command + ['--get-filename']
            sanitized_title_bytes = subprocess.check_output(get_filename_command)
            sanitized_title = os.path.splitext(sanitized_title_bytes.decode('utf-8').strip())[0]
        except:
            for f in sorted(os.listdir('.'), key=os.path.getmtime, reverse=True):
                if f.endswith('.mp3'):
                    sanitized_title = os.path.splitext(f)[0]
                    break

        downloaded_file = f"{sanitized_title}.mp3"

        print("\n‚ú® ¬°Descarga completada con √©xito!")
        print(f"   Archivo guardado como: {downloaded_file}")
        print("\n‚ö†Ô∏è IMPORTANTE: Revisa la descripci√≥n del video en YouTube para asegurarte de que la licencia permite su uso y si requiere atribuci√≥n.")
        print(f"   URL del video: {video_url}")

    except subprocess.CalledProcessError as e:
        print(f"\nüî¥ yt-dlp ha fallado. Error: {e}")
    except Exception as e:
        print(f"\nüî¥ Ha ocurrido un error inesperado: {e}")

# --- Ejecuci√≥n Principal ---
final_search_query = get_search_query(query_category)
buscar_y_descargar_con_yt_dlp(
    final_search_query,
    target_duration_minutes,
    duration_flexibility_minutes,
    randomize_song_selection
)

PROVA
"""

# @title üé¨ Unir Video con M√∫sica (Mezclado y con Volumen Ajustado)

# --- 1. IMPORTACI√ìN DE LIBRER√çAS ---
# Aseg√∫rate de tener moviepy instalado: pip install moviepy
import os
import math
import traceback
from moviepy.editor import (
    VideoFileClip,
    AudioFileClip,
    CompositeAudioClip,  # NUEVO: Importaci√≥n necesaria para mezclar audios
    concatenate_audioclips
)

# --- 2. PAR√ÅMETROS PRINCIPALES (AJUSTA ESTO) ---
# Usa el v√≠deo con subt√≠tulos generado en el paso anterior.
# Por ejemplo: "video_final_con_broll_y_subs.mp4"
VIDEO_INPUT_PATH = "video_final_con_broll_y_subs.mp4"

# Deja esto como None para que el script intente encontrar el .mp3 descargado.
MUSIC_INPUT_PATH = None

# NUEVO: Define qu√© tan fuerte quieres la m√∫sica de fondo (0.2 = 20% del volumen original)
# Puedes cambiar este valor seg√∫n necesites.
MUSIC_VOLUME = 0.05

# Nombre del archivo de video final.
VIDEO_OUTPUT_WITH_MUSIC_PATH = "video_final_con_musica_mezclada.mp4"

# --- 3. FUNCI√ìN PRINCIPAL PARA UNIR Y MEZCLAR AUDIO ---

def combine_video_music(
    video_path,
    music_path=None,
    output_path="video_final_con_musica_mezclada.mp4",
    music_volume=0.05  # NUEVO: Par√°metro para el volumen de la m√∫sica
):
    """
    Combina un video con un archivo de audio, mezcl√°ndolos.
    Conserva el audio original del video.
    Si la m√∫sica es m√°s larga, la recorta. Si es m√°s corta, la repite.
    """
    print(f"\n--- Uniendo y Mezclando Video y M√∫sica ---")

    if not os.path.exists(video_path):
        print(f"‚ùå Error: El archivo de video '{video_path}' no se encuentra.")
        return

    # Si no se especifica la m√∫sica, buscamos el √∫ltimo .mp3 descargado
    if music_path is None:
        try:
            mp3_files = sorted([f for f in os.listdir('.') if f.endswith('.mp3')], key=os.path.getmtime, reverse=True)
            if not mp3_files:
                print("‚ùå Error: No se ha especificado un archivo de m√∫sica y no se encontr√≥ ning√∫n .mp3 en la carpeta actual.")
                return
            music_path = mp3_files[0]
            print(f"üé∂ M√∫sica detectada autom√°ticamente: '{music_path}'")
        except FileNotFoundError:
             print("‚ùå Error: No se encontr√≥ la carpeta actual para buscar archivos .mp3.")
             return


    if not os.path.exists(music_path):
        print(f"‚ùå Error: El archivo de m√∫sica '{music_path}' no se encuentra.")
        return

    # Usamos variables con 'None' inicial para el bloque finally
    video_clip = music_clip = final_music_clip = video_with_music = final_audio = None
    try:
        # Cargar clips
        video_clip = VideoFileClip(video_path)
        music_clip = AudioFileClip(music_path)

        video_duration = video_clip.duration
        music_duration = music_clip.duration

        print(f"Duraci√≥n del Video: {video_duration:.2f} segundos")
        print(f"Duraci√≥n de la M√∫sica: {music_duration:.2f} segundos")

        # Ajustar la duraci√≥n de la m√∫sica
        if music_duration > video_duration:
            print("-> M√∫sica m√°s larga que el video. Recortando la m√∫sica...")
            final_music_clip = music_clip.subclip(0, video_duration)
        elif music_duration < video_duration:
            print("-> M√∫sica m√°s corta que el video. Repitiendo la m√∫sica en bucle...")
            # Usar math.ceil para redondear hacia arriba y asegurar cobertura total
            num_repeats = math.ceil(video_duration / music_duration)
            looped_music = concatenate_audioclips([music_clip] * int(num_repeats))
            final_music_clip = looped_music.subclip(0, video_duration)
        else:
            print("-> M√∫sica y video tienen duraciones similares.")
            final_music_clip = music_clip

        # --- INICIO DE LA L√ìGICA MODIFICADA ---

        # NUEVO: 1. Bajar el volumen de la m√∫sica de fondo
        print(f"-> Ajustando el volumen de la m√∫sica a {music_volume * 100}%...")
        final_music_clip = final_music_clip.volumex(music_volume)

        # NUEVO: 2. Comprobar si el video original tiene audio para mezclarlo
        if video_clip.audio is not None:
            print("-> Mezclando el audio original del video con la nueva m√∫sica...")
            # Creamos un clip de audio compuesto
            final_audio = CompositeAudioClip([video_clip.audio, final_music_clip])
        else:
            print("-> El video original no tiene audio. Se usar√° solo la m√∫sica de fondo.")
            final_audio = final_music_clip

        # NUEVO: 3. Asignar el audio (ya sea mezclado o solo la m√∫sica) al video
        video_with_music = video_clip.set_audio(final_audio)

        # --- FIN DE LA L√ìGICA MODIFICADA ---

        # Exportar el video final
        print(f"\n‚úÖ Renderizando el video final con audio mezclado a '{output_path}'...")
        video_with_music.write_videofile(
            output_path,
            codec='libx264',
            audio_codec='aac',
            fps=video_clip.fps,
            preset='medium',
            threads=os.cpu_count(),
            logger='bar'
        )
        print(f"\n‚ú® ¬°Proceso completado! Video final guardado en: '{output_path}'")

    except Exception as e:
        print(f"\nüî¥ Error durante la combinaci√≥n de video y m√∫sica: {str(e)}")
        traceback.print_exc()

    finally:
        # Asegurarse de cerrar todos los clips para liberar memoria
        print("\n-> Limpiando recursos...")
        if video_clip: video_clip.close()
        if music_clip: music_clip.close()
        if final_music_clip: final_music_clip.close()
        if final_audio: final_audio.close()
        if video_with_music: video_with_music.close()


# --- Ejecuci√≥n Principal ---
# Aseg√∫rate de que VIDEO_INPUT_PATH apunta al video correcto.
# Ajusta MUSIC_VOLUME si la m√∫sica sigue muy alta o muy baja.
combine_video_music(
    VIDEO_INPUT_PATH,
    MUSIC_INPUT_PATH,
    VIDEO_OUTPUT_WITH_MUSIC_PATH,
    MUSIC_VOLUME
)

"""# Si vols zooms:

from moviepy.editor import *
import random

# --- PAR√ÅMETROS DE CONFIGURACI√ìN ---
# Reemplaza "tu_video.mp4" con el nombre de tu archivo de v√≠deo.
nombre_video_original = "video_final_con_musica_mezclada.mp4"

# Nombre que tendr√° el v√≠deo final editado.
nombre_video_final = "video_dinamico_final.mp4"

# Nivel de zoom (1.1 = 10% de zoom, 1.15 = 15%). Se recomienda un valor sutil.
nivel_max_zoom = 1.1

# Duraci√≥n de los segmentos (en segundos). El c√≥digo usar√° valores aleatorios
# entre el m√≠nimo y el m√°ximo para que los cortes se sientan m√°s naturales.
duracion_min_segmento = 3.0
duracion_max_segmento = 7.0
# ------------------------------------


def aplicar_zoom_suave(clip, nivel_zoom):
  '''
  Aplica un zoom al centro del clip.
  '''
  w, h = clip.size
  
  # Calculamos el nuevo tama√±o del frame (m√°s peque√±o para simular el zoom)
  new_w = w / nivel_zoom
  new_h = h / nivel_zoom
  
  # Crop (recorte) centrado
  clip_zoomed = clip.fx(vfx.crop, width=new_w, height=new_h, x_center=w/2, y_center=h/2)
  
  # Se redimensiona al tama√±o original para que ocupe toda la pantalla
  return clip_zoomed.resize((w, h))

print("Cargando el v√≠deo...")
try:
    video_completo = VideoFileClip(nombre_video_original)
except Exception as e:
    print(f"Error al cargar el v√≠deo. Aseg√∫rate de que el archivo '{nombre_video_original}' se ha subido correctamente.")
    print(f"Detalle del error: {e}")
else:
    clips_procesados = []
    tiempo_actual = 0
    plano_con_zoom = False # Para alternar entre plano normal y con zoom

    print("Procesando el v√≠deo y aplicando efectos...")
    while tiempo_actual < video_completo.duration:
      # Duraci√≥n aleatoria para este segmento
      duracion_segmento = random.uniform(duracion_min_segmento, duracion_max_segmento)
      
      # Aseguramos no pasarnos de la duraci√≥n total del v√≠deo
      fin_segmento = min(tiempo_actual + duracion_segmento, video_completo.duration)
      
      # Extraemos el segmento del v√≠deo original
      subclip = video_completo.subclip(tiempo_actual, fin_segmento)
      
      if plano_con_zoom:
        # Aplicamos el efecto de zoom a este segmento
        clips_procesados.append(aplicar_zoom_suave(subclip, nivel_max_zoom))
      else:
        # Este segmento se queda con el plano original
        clips_procesados.append(subclip)
        
      # Alternamos para el siguiente segmento
      plano_con_zoom = not plano_con_zoom
      tiempo_actual = fin_segmento

    print("Uniendo los segmentos procesados...")
    video_final = concatenate_videoclips(clips_procesados)

    print(f"Exportando el v√≠deo final como '{nombre_video_final}'...")
    # Usamos presets para optimizar la velocidad y compatibilidad
    video_final.write_videofile(nombre_video_final, codec='libx264', audio_codec='aac', temp_audiofile='temp-audio.m4a', remove_temp=True)

    print("¬°Proceso completado con √©xito!")
"""

# @title ‚¨ÜÔ∏è Pujar v√≠deo a Google Drive

from google.colab import drive
import os

# 1. Montar Google Drive
# Aix√≤ demanar√† permisos per connectar-se al teu compte de Drive.
print("Muntant Google Drive...")
drive.mount('/content/drive')
print("‚úÖ Google Drive muntat.")

# 2. Definir la ruta de la carpeta on es guardar√† el v√≠deo
# Pots canviar 'videos editats' per la carpeta que vulguis dins del teu Drive.
# Si la carpeta no existeix, es crear√†.
drive_folder_path = '/content/drive/My Drive/videos editats'

# 3. Assegurar-se que la carpeta existeix
print(f"Verificant si la carpeta '{drive_folder_path}' existeix...")
os.makedirs(drive_folder_path, exist_ok=True)
print("‚úÖ Carpeta de destinaci√≥ preparada.")

# 4. Definir el nom del fitxer de v√≠deo que vols pujar
# Aquesta variable ha de coincidir amb el nom del fitxer de v√≠deo final que has generat
# en els passos anteriors (per exemple, "video_final_con_musica_mezclada.mp4" o "video_dinamico_final.mp4").
# **¬°IMPORTANT!** Canvia el nom del fitxer d'origen si has usat un nom diferent.
source_video_path = "video_final_con_musica_mezclada.mp4" # <-- CANVIA AIX√í SI CAL

# 5. Definir la ruta completa del fitxer de destinaci√≥ a Drive
destination_video_path = os.path.join(drive_folder_path, os.path.basename(source_video_path))

# 6. Copiar el fitxer a Google Drive
if os.path.exists(source_video_path):
    print(f"Pujant '{source_video_path}' a '{destination_video_path}'...")
    # Utilitzem una comanda de shell per copiar el fitxer
    !cp "{source_video_path}" "{destination_video_path}"
    print(f"‚úÖ ¬°Fitxer pujat amb √®xit a Google Drive!")
else:
    print(f"‚ùå Error: El fitxer d'origen '{source_video_path}' no es troba. Assegura't que el nom √©s correcte i que el v√≠deo s'ha generat.")